"""
engeto-project-3.py: třetí projekt do Engeto Online Python Akademie, Elections Scraper

author: Michaela Jochcová (Kerberová)
email: michaela.kerberova@gmail.com
discord: k.michaela
"""

import os
import sys
import csv
import requests
from bs4 import BeautifulSoup as BS
from typing import List

# main function
def main():
    pass

# checking for correctly entered inputs
# checking for correctly entered url address
def get_url() -> str:
    url_check = "https://www.volby.cz/pls/ps2017nss/ps32"
    if len(sys.argv) != 3:
        print("Please, enter the correct inputs: 'url' 'file_name.csv'.")
        sys.exit()
    url_adress = sys.argv[1]
    if url_check not in url_adress:
        print("Wrong URL entered.")
        sys.exit()
    try:
        response = requests.get(url_adress, timeout=5)
        response.raise_for_status()
    except requests.RequestException:
        print("Invalid or unreachable URL entered. Check your internet connection.")
        sys.exit()
    return url_adress

# checking for correctly entered file name
def get_file_name() -> str:
    if len(sys.argv) != 3:
        print("Please, enter the correct inputs: 'url' 'file_name.csv'.")
        sys.exit()
    file_name = sys.argv[2]
    if not file_name.endswith(".csv"):
        print("Wrong file format entered.")
        sys.exit()
    if os.path.exists(file_name):
        print(f"Entered file name '{file_name}' already exists.")
        sys.exit()
    return file_name



# Checking internet connection using available address
def check_internet_connection():
    try:
        requests.get("https://www.google.com", timeout=5)
        return True
    except requests.ConnectionError:
        return False

# Checking response of a specific website
def get_response(entered_url):
    if not check_internet_connection():
        print("No internet connection")
        sys.exit()
    
    try:
        with requests.session() as s:
            url_request = s.get(entered_url)
    except requests.ConnectionError:
        print("No response from the website")
        sys.exit()
    else:
        return url_request

# html parsing
def make_soup(url_request):
    return BS(url_request.text, "html.parser")

# create a dictionary - keys: party names, values: votes
def find_candidate_parties():
    pass

# city ​​name search
def get_city_name():
    pass

# getting selected data from website
def get_selected_data():
    pass

# saving data to csv file
def print_to_csv():
    pass

if __name__ == "__main__":
    main()