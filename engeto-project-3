"""
engeto-project-3.py: třetí projekt do Engeto Online Python Akademie, Elections Scraper

author: Michaela Jochcová (Kerberová)
email: michaela.kerberova@gmail.com
discord: k.michaela
"""

import os
import sys
import csv
import requests
from bs4 import BeautifulSoup as BS
from typing import List

# main function
def main():
    pass

# checking correct number of arguments
def check_arguments() -> None:
    if len(sys.argv) != 3:
        print("Please, enter the correct arguments: 'url' 'file_name.csv'.")
        sys.exit()

# checking for correctly entered url address
def validate_url_adress() -> str:
    check_arguments()
    url_check = "https://www.volby.cz/pls/ps2017nss/ps32"
    url_adress = sys.argv[1]
    if url_check not in url_adress:
        print("Wrong URL entered.")
        sys.exit()
    else:
        return url_adress

# checking for correctly entered file name
def validate_file_name() -> str:
    check_arguments()
    file_name = sys.argv[2]
    if not file_name.endswith(".csv"):
        print("Wrong file format entered.")
        sys.exit()
    if os.path.exists(file_name):
        print(f"Entered file name '{file_name}' already exists.")
        sys.exit()
    return file_name

# checking internet connection and URL availability
def get_response(url_adress: str):
    try:
        response = requests.get(url_adress, timeout=5)
        response.raise_for_status()
    except requests.RequestException:
        print("Invalid or unreachable URL entered. Please try again later.")
        sys.exit()
    return response
        
# html parsing
def make_soup(response: requests.Response) -> BS:
    return BS(response.text, "html.parser")

# city ​​name search
def get_city_name(parsed: BS) -> str:
    for element in parsed.select("h3"):
        if "obec" in element.text.casefold():
            return element.text.strip().split(": ")[-1]
    return ""

# create a dictionary where keys are party names values ​​are votes
def find_candidate_parties(parsed) -> dict:
    parties = {}
    for table in parsed.find_all("table")[1:]:
        for key in table.select("td.overflow_name"):
            value = key.find_next_sibling("td").text
            parties[key.text] = value
    return parties

# getting selected data from website
def get_selected_data():
    pass

# saving data to csv file
def print_to_csv():
    pass

if __name__ == "__main__":
    main()